{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m pip install detectron2 -f \\\n  https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from bs4 import BeautifulSoup as bs\n#cuda 10.1\nimport torch, torchvision\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\nimport glob\n\nimport os\nimport ntpath\nimport numpy as np\nimport cv2\nimport random\nimport itertools\nimport pandas as pd\nfrom tqdm import tqdm\nimport urllib\nimport json\nimport PIL.Image as Image\n\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.structures import BoxMode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\n\npath_cpy = \"/kaggle/input/face-mask-detection\"\n\n# shutil.copytree(path_cpy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper functions"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def gen_box(obj):\n#     Getting bounding box coordinates\n    xmin = int(obj.find('xmin').text)\n    xmax = int(obj.find('xmax').text)\n    ymin = int(obj.find('ymin').text)\n    ymax = int(obj.find('ymax').text)\n    \n    return [xmin, ymin, xmax, ymax]\n\ndef gen_label(obj):\n    if obj.find('name').text == \"with_mask\":\n        return \"mask\" #     for without_mask label set to 1\n    elif obj.find('name').text == \"mask_weared_incorrect\":\n        return \"incorrect_mask\"     # for mask_weared_incorrect label set to 2\n    return \"no_mask\" #     for without_mask label set to 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting Data from xml file"},{"metadata":{"trusted":true},"cell_type":"code","source":"coordinates = []\nlabels = []\nname= []\nsize = []\ndef gen_list(path):\n    xml_list  = list(sorted(os.listdir(path+\"/annotations\")))\n    img_list = list(sorted(os.listdir(path+\"/images\")))\n    total = len(img_list)\n    assert len(img_list) == len(xml_list)\n    counter = 0\n    for xml in xml_list:\n        with open(path+f\"/annotations/{xml}\") as file:\n            data = file.read()\n            soup = bs(data, \"xml\")\n            xml_objs = soup.find_all('object')\n            counter +=1\n            for i in xml_objs:\n                coordinates.append(gen_box(i)) \n                labels.append(gen_label(i))\n                name.append(soup.find('filename').text)\n        print(f\"file processed {counter} / {total}...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_list(path_cpy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xml_list  = list(sorted(os.listdir(path_cpy+\"/annotations\")))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making DataFrame from data extracted from XML"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['name'] = name\ndf['labels'] = labels\n# initializing labels\ndf['xmin'] = 0\ndf['ymin'] = 0\ndf['xmax'] = 0\ndf['ymax'] = 0\ndf['height'] = np.zeros(len(df['name']))\ndf['width'] = np.zeros(len(df['name']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assigning values to columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,(xmin,ymin,xmax,ymax) in enumerate(coordinates):\n    df['xmin'][i] = xmin\n    df['ymin'][i] = ymin\n    df['xmax'][i] = xmax\n    df['ymax'][i] = ymax\n\n\nfor i,fname in enumerate(name):\n    img = cv2.imread(path_cpy+'/images/'+fname)\n    height = img.shape[0]\n    width = img.shape[1]\n    df['height'][i] = height\n    df['width'][i] = width","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data into Train and Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_files = df.name.unique()\n\ntrain_files = set(np.random.choice(unique_files, int(len(unique_files) * 0.95), replace=False))\ntrain_df = df[df.name.isin(train_files)]\ntest_df = df[~df.name.isin(train_files)]\nclasses = df.labels.unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating function that formats data in COCO Dateset format"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_dataset_function(df,classes):\n    data_list = []\n    for i,fname in enumerate(df['name'].unique()):\n        record = dict()\n        #gtetting all rows with nmae as fnmae\n        image_df = df[df['name']==fname]\n        #image path\n        img_path = path_cpy +'/images/'+fname\n        #entring recprds\n        record['file_name'] = img_path\n        record['image_id'] = i\n        record['height'] = int(image_df.iloc[0].height)\n        record['width'] = int(image_df.iloc[0].width)\n        \n        objs = []\n        \n        for _,row in image_df.iterrows():\n            \n        \n            xmin = int(row.xmin)\n            ymin = int(row.ymin)\n            xmax = int(row.xmax)\n            ymax = int(row.ymax)\n\n            poly = [\n            (xmin, ymin), (xmax, ymin),\n            (xmax, ymax), (xmin, ymax)\n            ]\n            poly = list(itertools.chain.from_iterable(poly))\n\n            obj = {\n            \"bbox\": [xmin, ymin, xmax, ymax],\n            \"bbox_mode\": BoxMode.XYXY_ABS,\n            \"segmentation\": [poly],\n            \"category_id\": classes.index(row.labels),\n            \"iscrowd\": 0\n            }\n            objs.append(obj)\n\n        record[\"annotations\"] = objs\n        data_list.append(record)\n    return data_list\n\n          \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df),len(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Registering Datasets"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for d in [\"train\", \"val\"]:\n  DatasetCatalog.register(\"data_\" + d, lambda d=d: my_dataset_function(train_df if d == \"train\" else test_df, classes))\n  MetadataCatalog.get(\"data_\" + d).set(thing_classes=classes)\n\nstatement_metadata = MetadataCatalog.get(\"data_train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"statement_metadata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CocoTrainer(DefaultTrainer):\n\n  @classmethod\n  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n\n    if output_folder is None:\n        os.makedirs(\"coco_eval\", exist_ok=True)\n        output_folder = \"coco_eval\"\n\n    return COCOEvaluator(dataset_name, cfg, False, output_folder)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initializing and setting cfg"},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = get_cfg()\n\ncfg.merge_from_file(\n  model_zoo.get_config_file(\n    \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n  )\n)\n\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n  \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n)\ncfg.DATASETS.TRAIN = (\"data_train\",)\ncfg.DATASETS.TEST = (\"data_val\",)\ncfg.DATALOADER.NUM_WORKERS = 4\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.001\ncfg.SOLVER.WARMUP_ITERS = 1000\ncfg.SOLVER.MAX_ITER = 1500\ncfg.SOLVER.STEPS = (1000, 1500)\ncfg.SOLVER.GAMMA = 0.05\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\ncfg.TEST.EVAL_PERIOD = 500","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Detectron2 "},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\ntrainer = CocoTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving model"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(trainer.model, 'checkpoint.pth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's try our model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"im = cv2.imread('../input/face-mask-detection/images/maksssksksss110.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\npredictor = DefaultPredictor(cfg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"evaluator = COCOEvaluator(\"data_val\", cfg, False, output_dir=\"./output/\")\nval_loader = build_detection_test_loader(cfg, \"data_val\")\ninference_on_dataset(trainer.model, val_loader, evaluator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs = predictor(im)\nv = Visualizer(\nim[:, :, ::-1],\nmetadata=statement_metadata,\nscale=1.,\ninstance_mode=ColorMode.IMAGE\n)\ninstances = outputs[\"instances\"].to(\"cpu\")\ninstances.remove('pred_masks')\nv = v.draw_instance_predictions(instances)\nresult = v.get_image()[:, :, ::-1]\nfile_name = ntpath.basename('test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(13,10))\nplt.imshow(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('./output')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.copy('./output/model_final.pth','./')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}